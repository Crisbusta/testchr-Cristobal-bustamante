## Contenido del repositorio

El repositorio es un proyecto desarrollado en Django 4 + PostgreSQL + Docker. El uso de docker se debe a la facilidad que tiene docker de instalar dependencias y encapsular todo el proyecto en un contenedor.

El proyecto tiene una sola aplicaci贸n llamada testchr, la cual se encarga completamente de la tarea 1 y parcialmente de la tarea 2.

##### Comentarios tarea 1:
En esta tarea me surgieron dudas principalmente sobre cu谩les datos manejar del json, finalmente decid铆 trabajar solo con los datos en 'stations' omitiendo el array 'extras'. 
La funci贸n 'save_stations_data' se encarga de obtener los datos de la Api e insertarlos en la base de datos.

Adem谩s, realic茅 los dos items opcionales de la tarea. Cre茅 una vista en el administrador y una vista personalizada que posee una tabla mostrando los datos con paginaci贸n inclu铆da, la funci贸n 'display_stations_data' se encarga de esto.

##### Comentarios tarea 2:
Esta tarea fue considerablemente m谩s desafiante que la tarea 1. En primer lugar se desarrolla el script 'scraping-proyectos.py' que se encarga de obtener la informaci贸n de la tabla en la url entregada. 
Todo bien hasta aqu铆, el problema comienza cuando veo que son 2844 paginaciones y obtener toda la informaci贸n tardar铆a demasiado si lo hac铆a iterando. 
Es por esto que decid铆 utilizar hilos (Threads) para agilizar la obtenci贸n de datos, a煤n as铆 el script de obtenci贸n de datos tarda +10min en obtener toda la informaci贸n y guardarla en un archivo json.

Para poder insertar toda la data contenida en el json me di la libertad de instalar la librer铆a 'django-import-export' la cual agrega un bot贸n de importaci贸n en el administrador de django y nos permite importar masivamente distintos tipos de archivos, entre ellos json.

Con el objetivo de optimizar el tiempo de qui茅n se encargar谩 de probar este proyecto se adjuntan dos archivos json, "tabla_datos.json" posee toda la data extra铆da del web scraping, en cambio, "test.json" posee solo 20 registros, esto con el prop贸sito de agilizar la importaci贸n con fines de pruebas.
Importa el que desees.

Adem谩s, realic茅 los dos items opcionales de la tarea. Cre茅 una vista en el administrador y una vista personalizada que posee una tabla mostrando los datos con paginaci贸n inclu铆da, la funci贸n 'display_projects_data' se encarga de esto.


## 驴C贸mo utilizar este repositorio?
Para ejecutar el proyecto se deben seguir los siguientes pasos:

1. Descargar el repositorio
2. Extraer la carpeta
3. Iniciar docker
4. Abrir la terminal en la ruta donde se extrajo la carpeta
5. Ejecutar el comando ``` docker-compose run web python manage.py makemigrations```
6. Ejecutar el comando ``` docker-compose up --build```
 6.1 Encontr茅 un peque帽o bug y no pude solucionarlo  La consola entregar谩 un error al ejecutar ```docker-compose up --build``` por primera vez, simplemente ejecuta el comando de nuevo y el proyecto se ejecutar谩.
7. Crear un usuario para el admin, ejecutar el comando ``` docker-compose run web python manage.py createsuperuser```
8. Ingresar a la ruta http://localhost:8000/testchr/ (En este momento se obtienen los datos de la Api de la tarea 1 y se insertan en la base de datos)
9. Para ver los datos insertados, ingresar a la ruta: http://localhost:8000/testchr/stations o en su defecto revisar los datos en el admin: http://localhost:8000/admin/testchr/station/
10. Ingresar a la ruta http://localhost:8000/admin/testchr/project/ e importar el archivo json que se encuentra en la ra铆z del proyecto. El archivo "tabla_datos.json" posee toda la data extra铆da del web scraping, el archivo "test.json" posee solo 20 registros, esto con el prop贸sito de agilizar la importaci贸n con fines de pruebas. Importa el que desees. Pasos para importar:
10.1. ![Descripci贸n de la imagen](https://scontent.fscl11-2.fna.fbcdn.net/v/t39.30808-6/331299149_586945596345508_3168636580135746402_n.jpg?stp=cp6_dst-jpg&_nc_cat=101&ccb=1-7&_nc_sid=730e14&_nc_ohc=iCjmvPIgmkUAX9l3C0R&_nc_ht=scontent.fscl11-2.fna&oh=00_AfD2nHlmuwRGy6sDf3lV06Ml5-k5EC3IQAsYZM9eW8rulQ&oe=63F4484E)
10.2.![Descripci贸n de la imagen](https://scontent.fscl11-1.fna.fbcdn.net/v/t39.30808-6/331933886_1413855832485841_4473111276968359931_n.jpg?stp=cp6_dst-jpg&_nc_cat=110&ccb=1-7&_nc_sid=730e14&_nc_ohc=lRVx-Z9cy1MAX9r9Z7m&_nc_ht=scontent.fscl11-1.fna&oh=00_AfBOr8mR14B94H1bBAPhLDpDcHHBQS9REtMPEWugBaU0pQ&oe=63F43866)
10.3.![Descripci贸n de la imagen](https://scontent.fscl11-2.fna.fbcdn.net/v/t39.30808-6/331549010_3758552564371872_5281027802686922001_n.jpg?stp=cp6_dst-jpg&_nc_cat=103&ccb=1-7&_nc_sid=730e14&_nc_ohc=uf9BfrhqNuQAX_AvURF&_nc_ht=scontent.fscl11-2.fna&oh=00_AfBgrZqj-RVqb3GPqiArJDVkylgp_EE9PpKi63YcRDxeig&oe=63F4A86D)
11. Una vez se haya importado el contenido del json a la base de datos podemos ingresar a la ruta http://localhost:8000/testchr/projects en la cual hay una tabla que muestra todos los datos importados o en su defecto revisar los datos en el admin: http://localhost:8000/admin/testchr/project/




